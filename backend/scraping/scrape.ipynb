{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "path_prefix = \"dump/\"\n",
    "base_url = \"http://www.streamlinerschedules.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded\n"
     ]
    }
   ],
   "source": [
    "def download_track_pages():\n",
    "    track_pages = [f\"concourse/track{i}\" for i in range(1, 13)]\n",
    "    for page in track_pages:\n",
    "        Path(path_prefix + page).mkdir(exist_ok=True, parents=True)\n",
    "        with open(f\"{path_prefix}{page}/index.html\", \"wb+\") as f:\n",
    "            f.write(requests.get(f\"{base_url}{page}/index.html\").content)\n",
    "\n",
    "check_file = Path(f\"{path_prefix}/concourse/track1/index.html\")\n",
    "\n",
    "if check_file.exists() and check_file.stat().st_size > 0:\n",
    "    print(\"Already downloaded\")\n",
    "else:\n",
    "    # download_track_pages()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_pages = [f\"concourse/track{i}/index.html\" for i in range(1, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_prefix + track_pages[0], \"rb\") as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list like \"birmspecial194112.html\", \"carolinaspecial196410.html\", etc\n",
    "def get_train_links(soup):\n",
    "    relative_links = []\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href is not None and \"..\" not in href and \"http://\" not in href:\n",
    "            relative_links.append(href)\n",
    "    return relative_links\n",
    "\n",
    "def get_link(relative_link, page):\n",
    "    page = page.rstrip(\"index.html\")\n",
    "    return f\"{base_url}{page}{relative_link}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_child_pages(page):\n",
    "    with open(path_prefix + page, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "        links = get_train_links(soup)\n",
    "        for link in links:\n",
    "            with open(f\"{path_prefix}{page.rstrip('index.html')}/{link}\", \"wb+\") as f:\n",
    "                f.write(requests.get(get_link(link, page)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_files = []\n",
    "for page in track_pages:\n",
    "    with open(path_prefix + page, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "        links = get_train_links(soup)\n",
    "        for link in links:\n",
    "            file_location = f\"{path_prefix}{page.rstrip('index.html')}{link}\"\n",
    "            all_train_files.append(file_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_get_schedule_from_row(stops, row, train_nums):\n",
    "    if train_nums is None:\n",
    "        return False\n",
    "    try:\n",
    "        # Don't differentiate between departure and arrival time, since they can be on different lines.\n",
    "        if row.find(\"td\", class_=\"times\") is None or len(row.find_all(\"td\", class_=\"times\")) != len(train_nums):\n",
    "            return False\n",
    "        \n",
    "        possible_miles = row.find_all(\"td\", class_=\"miles\")\n",
    "        if len(possible_miles) == 2:\n",
    "            miles = row.find_all(\"td\", class_=\"miles\")[1]\n",
    "        elif len(possible_miles) == 1:\n",
    "            miles = row.find(\"td\", class_=\"miles\")\n",
    "        else:\n",
    "            return False\n",
    "        station = miles.findNext('td')\n",
    "\n",
    "        times = row.find_all(\"td\", class_=\"times\")\n",
    "        for num, time in zip(train_nums, times):\n",
    "            time = time.text.replace(\"D\", \"\").replace(\"R\", \"\").replace(\"\\n\", \" \").strip()\n",
    "            if len(time) == 0:\n",
    "                continue\n",
    "            stops.loc[len(stops)] = [num, station.text.strip(), time, miles.text.strip()]\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(row, e)\n",
    "        raise e\n",
    "\n",
    "def parse_schedule(schedule_filename):\n",
    "    with open(schedule_filename, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    train_name = soup.find(\"h1\").text\n",
    "\n",
    "    # TODO: Date\n",
    "    description_element = soup.find('h3', id='rrdate')\n",
    "    table = soup.find('table')\n",
    "\n",
    "\n",
    "    stops = pd.DataFrame(columns=[\"train_number\", \"station\", \"time\", \"miles\"])\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "\n",
    "    train_nums = None\n",
    "    num_rows_skipped = 0\n",
    "    for row in rows:\n",
    "        if row.find(\"td\", class_=\"trainnum\") is not None:\n",
    "            # TODO: Map train number since they continue off each other\n",
    "            train_nums = [t.text.strip() for t in row.find_all(\"td\", class_=\"trainnum\")]\n",
    "            continue\n",
    "\n",
    "        added_schedule = maybe_get_schedule_from_row(stops, row, train_nums)\n",
    "        if not added_schedule:\n",
    "            num_rows_skipped += 1\n",
    "    print(train_name, num_rows_skipped, \"rows skipped\")\n",
    "    \n",
    "    return train_name, stops\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parse_schedule(\"dump/concourse/track1/birmspecial194112.html\")[1]\n",
    "# parse_schedule(\"dump/concourse/track1/carolinaspecial196410.html\")\n",
    "# parse_schedule(\"dump/concourse/track1/cityneworl194706.html\")\n",
    "# parse_schedule(\"dump/concourse/track1/cityneworl197104.html\")\n",
    "# parse_schedule(\"dump/concourse/track1/georgewash196706.html\")\n",
    "# parse_schedule(\"dump/concourse/track1/gulfcoastrebel195008.html\")\n",
    "# parse_schedule(\"dump/concourse/track3/erieltd195103.html\")\n",
    "# parse_schedule(\"dump/concourse/track11/indianpacific198805.html\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birmingham Special 9 rows skipped\n",
      "The Carolina Special 9 rows skipped\n",
      "The City of Memphis 1 rows skipped\n",
      "The City of New Orleans 10 rows skipped\n",
      "The City of New Orleans 9 rows skipped\n",
      "The Crescent 14 rows skipped\n",
      "The Southern Crescent 12 rows skipped\n",
      "The Southern Crescent 7 rows skipped\n",
      "The George Washington\n",
      "The F. F. V.\n",
      "The Sportsman 27 rows skipped\n",
      "The Georgian 13 rows skipped\n",
      "The Gulf Coast Rebel 8 rows skipped\n",
      "The Humming Bird 6 rows skipped\n",
      "The Humming Bird 27 rows skipped\n",
      "The Pan-American 11 rows skipped\n",
      "The Pan-American 10 rows skipped\n",
      "The Piedmont\n",
      "Trains 7 & 8\n",
      "Trains 3 & 4 6 rows skipped\n",
      "The Powhatan Arrow 5 rows skipped\n",
      "The Rebel 8 rows skipped\n",
      "The Rebel 6 rows skipped\n",
      "The Silver Comet 7 rows skipped\n",
      "The Southern Belle 4 rows skipped\n",
      "The Southern Belle 5 rows skipped\n",
      "The Southerner 8 rows skipped\n",
      "The Tennessean 16 rows skipped\n",
      "The Tamiami Champion (East Coast) 10 rows skipped\n",
      "The Tamiami Champion (West Coast) 10 rows skipped\n",
      "The Champion 9 rows skipped\n",
      "The City of Miami 2 rows skipped\n",
      "The City of Miami 14 rows skipped\n",
      "The  Del-Mar-Va Express 9 rows skipped\n",
      "The  Dixie Flagler 5 rows skipped\n",
      "The Florida Special 9 rows skipped\n",
      "The  Gulf Wind 3 rows skipped\n",
      "The Gulf Wind 3 rows skipped\n",
      "The  Havana Special 19 rows skipped\n",
      "The  Kansas City-Florida Special 8 rows skipped\n",
      "The \n",
      "\"New Royal Palm\"\n",
      "The Michigan Special/The Ohio Special\n",
      "The Midnight Special\n",
      " 26 rows skipped\n",
      "The Orange Blossom Special 12 rows skipped\n",
      "The Orange Blossom Special 10 rows skipped\n",
      "The Silver Star 5 rows skipped\n",
      "The South Wind 5 rows skipped\n",
      "The South Wind 6 rows skipped\n",
      "The Black Diamond 3 rows skipped\n",
      "The Capitol Limited 8 rows skipped\n",
      "The Capitol Limited\n",
      "The Columbian\n",
      "The Ambassador\n",
      " 7 rows skipped\n",
      "The Capitol Limited\n",
      " 5 rows skipped\n",
      "The Commodore Vanderbilt\n",
      "The Advance Commodore\n",
      "Vanderbilt\n",
      " 12 rows skipped\n",
      "The Congressionals 1 rows skipped\n",
      "The Crusader 2 rows skipped\n",
      "The Erie Limited 35 rows skipped\n",
      "The Federal Express 20 rows skipped\n",
      "The Federal 12 rows skipped\n",
      "The Flying Yankee 16 rows skipped\n",
      "The General 3 rows skipped\n",
      "The General 2 rows skipped\n",
      "The Keystones 2 rows skipped\n",
      "The Knickerbocker 34 rows skipped\n",
      "The Lake Cities 5 rows skipped\n",
      "The Lake Cities 16 rows skipped\n",
      "The Liberty Limited 5 rows skipped\n",
      "The Liberty Limited 4 rows skipped\n",
      "The Manhattan Limited\n",
      "The Pennsylvania\n",
      "Limited 3 rows skipped\n",
      "The Merchants Limited 3 rows skipped\n",
      "The Merchants Limited 1 rows skipped\n",
      "The Metroliners 8 rows skipped\n",
      "The Metroliners 1 rows skipped\n",
      "The National Limited 20 rows skipped\n",
      "The New England States 12 rows skipped\n",
      "The Penn Texas 10 rows skipped\n",
      "The Phoebe Snow 7 rows skipped\n",
      "The\n",
      "Phoebe Snow 19 rows skipped\n",
      "The\n",
      "Potatoland Special 5 rows skipped\n",
      "The Royal BlueThe Columbian 1 rows skipped\n",
      "The St. Louisan 19 rows skipped\n",
      "The Senator 2 rows skipped\n",
      "The \"Spirit of St. Louis\"\n",
      "The Jeffersonian 2 rows skipped\n",
      "The Trail Blazer 7 rows skipped\n",
      "The Westerner\n",
      "The New Yorker 15 rows skipped\n",
      "The Wolverine 24 rows skipped\n",
      "The Abraham Lincoln\n",
      "The\n",
      "Ann Rutledge 1 rows skipped\n",
      "The Arrow 6 rows skipped\n",
      "The Blue Bird 2 rows skipped\n",
      "The\n",
      "Streamliner, City of\n",
      "Salina 11 rows skipped\n",
      "The \"400\" 2 rows skipped\n",
      "The Green Diamond 2 rows skipped\n",
      "The Mercury 1 rows skipped\n",
      "Trains 3\n",
      "& 4 3 rows skipped\n",
      "The Eagle 2 rows skipped\n",
      "The Missouri River Eagle 2 rows skipped\n",
      "The Nickel Plate Limited 4 rows skipped\n",
      "The Peoria Rocket\n",
      "The Des Moines Rocket 4 rows skipped\n",
      "The Pere Marquettes 1 rows skipped\n",
      "The Pioneer Zephyr 3 rows skipped\n",
      "The Thoroughbred 2 rows skipped\n",
      "The Twin Zephyrs 2 rows skipped\n",
      "The Twin Zephyrs 2 rows skipped\n",
      "The \"Wabash Cannon Ball\" 5 rows skipped\n",
      "The Broadway Limited 2 rows skipped\n",
      "The Broadway Limited 2 rows skipped\n",
      "The Broadway Limited 1 rows skipped\n",
      "The Broadway Limited 2 rows skipped\n",
      "The\n",
      "California Zephyr 18 rows skipped\n",
      "The\n",
      "California Zephyr 18 rows skipped\n",
      "The Canadian 15 rows skipped\n",
      "The Canadian 2 rows skipped\n",
      "The\n",
      "Streamliner, City of\n",
      "Los Angeles 10 rows skipped\n",
      "The City\n",
      "of\n",
      "Los Angeles\n",
      "The Challenger 17 rows skipped\n",
      "The City\n",
      "of\n",
      "Los Angeles 15 rows skipped\n",
      "The City\n",
      "of\n",
      "Los Angeles\n",
      "The Challenger\n",
      "The City of\n",
      "Denver\n",
      "The City of Kansas City\n",
      "The City of\n",
      "Portland\n",
      "The City of San\n",
      "Francisco\n",
      "[aka: The \"City of\n",
      "Everywhere!\"] 32 rows skipped\n",
      "The Daylight 3 rows skipped\n",
      "The Coast Daylight 5 rows skipped\n",
      "The Hiawatha 4 rows skipped\n",
      "The Hiawathas 5 rows skipped\n",
      "The Hiawathas 5 rows skipped\n",
      "The North Coast Limited 20 rows skipped\n",
      "The North Coast Limited 30 rows skipped\n",
      "The Panama Limited 17 rows skipped\n",
      "The Panama Limited 10 rows skipped\n",
      "The Panama Limited\n",
      "The Magnolia Star\n",
      " 9 rows skipped\n",
      "The Panama Limited 8 rows skipped\n",
      "The Silver Meteor 9 rows skipped\n",
      "The Silver Meteor 10 rows skipped\n",
      "The Silver Meteor 4 rows skipped\n",
      "The Super Chief 11 rows skipped\n",
      "The Super Chief 11 rows skipped\n",
      "The Super Chief 14 rows skipped\n",
      "The Super Chief\n",
      "El\n",
      "Capitan 25 rows skipped\n",
      "The Super Chief\n",
      "El\n",
      "Capitan 35 rows skipped\n",
      "The 20th Century Limited 8 rows skipped\n",
      "The 20th Century Limited 1 rows skipped\n",
      "The 20th Century Limited 2 rows skipped\n",
      "The 20th Century Limited 1 rows skipped\n",
      "Error parsing dump/concourse/track5/mailto:eric@streamlinerschedules.com: 'NoneType' object has no attribute 'find_all'\n",
      "Trains 1 and 2\n",
      " 2 rows skipped\n",
      "The Atlantic Limited\n",
      "Dayliner RDC Service\n",
      " 12 rows skipped\n",
      "The Gull 16 rows skipped\n",
      "The International Limited 18 rows skipped\n",
      "The Streamlined Internationals\n",
      "Trains 358 & 359\n",
      " 22 rows skipped\n",
      "The Maple Leaf 7 rows skipped\n",
      "The Midnight Sun\n",
      " 1 rows skipped\n",
      "The MontrealerThe Washingtonian 10 rows skipped\n",
      "The Montreal Limited 3 rows skipped\n",
      "The Mountaineer\n",
      " 11 rows skipped\n",
      "The Ocean Limited 8 rows skipped\n",
      "The Ontarian 3 rows skipped\n",
      "The Red Wing\n",
      "The Alouette/Budd\n",
      "Highliner\n",
      " 3 rows skipped\n",
      "The Scotian 7 rows skipped\n",
      "The Super Continental 17 rows skipped\n",
      "The Butte Special\n",
      "The Yellowstone\n",
      "Special 6 rows skipped\n",
      "The Cascade 7 rows skipped\n",
      "The\n",
      "Streamliner, City of\n",
      "Portland 4 rows skipped\n",
      "The City of Portland 18 rows skipped\n",
      "The City of Portland 16 rows skipped\n",
      "The Empire Builder 10 rows skipped\n",
      "The Empire Builder 14 rows skipped\n",
      "The Golden Gates 9 rows skipped\n",
      "The Lark 8 rows skipped\n",
      "The Olympian 17 rows skipped\n",
      "The Olympian Hiawatha 14 rows skipped\n",
      "The Owl 5 rows skipped\n",
      "Seattle-Portland\n",
      "Pool Service 10 rows skipped\n",
      "Seattle-Portland\n",
      "Pool Service 6 rows skipped\n",
      "Seattle-Portland\n",
      "Pool Service 2 rows skipped\n",
      "The Rogue River 2 rows skipped\n",
      "The San Diegans 1 rows skipped\n",
      "The San Joaquin Daylight 4 rows skipped\n",
      "The San Joaquin Daylight\n",
      "The Sacramento\n",
      "Daylight 5 rows skipped\n",
      "The San Joaquin Daylight\n",
      "The Sacramento\n",
      "Daylight 5 rows skipped\n",
      "The Shasta Daylight 6 rows skipped\n",
      "The Spokane 8 rows skipped\n",
      "The West Coast 3 rows skipped\n",
      "The Western Star 39 rows skipped\n",
      "California\n",
      "Express 15 rows skipped\n",
      "The California\n",
      "Limited\n",
      " 17 rows skipped\n",
      "The California\n",
      "Limited 18 rows skipped\n",
      "The Chief 10 rows skipped\n",
      "The Chief 25 rows skipped\n",
      "The\n",
      "Streamliner, City of Denver 3 rows skipped\n",
      "The\n",
      "Streamliner, City of Denver 7 rows skipped\n",
      "The\n",
      "Domeliner, City of St. Louis 15 rows skipped\n",
      "The\n",
      "Domeliner, City of St. Louis 17 rows skipped\n",
      "The\n",
      "Streamliner, City of\n",
      "San Francisco 7 rows skipped\n",
      "The\n",
      "Streamliner, City of\n",
      "San Francisco 14 rows skipped\n",
      "The City\n",
      "of San\n",
      "Francisco 14 rows skipped\n",
      "The Colorado\n",
      "Eagle 6 rows skipped\n",
      "The Colorado\n",
      "Eagle 6 rows skipped\n",
      "The Denver\n",
      "Zephyr 12 rows skipped\n",
      "The Denver\n",
      "Zephyr 10 rows skipped\n",
      "The Denver\n",
      "Zephyr 8 rows skipped\n",
      "El\n",
      "Capitan 11 rows skipped\n",
      "El\n",
      "Capitan 11 rows skipped\n",
      "The Grand Canyon Limited\n",
      " 20 rows skipped\n",
      "The Grand Canyon\n",
      " 25 rows skipped\n",
      "Trains\n",
      "23 and 24\n",
      " 13 rows skipped\n",
      "The Los\n",
      "Angeles Limited\n",
      " 12 rows skipped\n",
      "Trains\n",
      "7-5 and 6-8\n",
      " 13 rows skipped\n",
      "Passenger\n",
      "Express 2 rows skipped\n",
      "The San\n",
      "Francisco Overland Limited\n",
      " 10 rows skipped\n",
      "The San\n",
      "Francisco Overland 16 rows skipped\n",
      "Trains\n",
      "27-9 and 10-28\n",
      "The Streamliner San\n",
      "Francisco Overland 12 rows skipped\n",
      "Trains\n",
      "11-15 and 16-12 (California Service)\n",
      "The Rio Grande Zephyr 10 rows skipped\n",
      "The Rocky\n",
      "Mountain Rocket 9 rows skipped\n",
      "The Royal\n",
      "Gorge\n",
      "The Prospector 12 rows skipped\n",
      "The Royal\n",
      "Gorge\n",
      "The Prospector 12 rows skipped\n",
      "The San\n",
      "Francisco Chief 40 rows skipped\n",
      "The San\n",
      "Francisco Chief 42 rows skipped\n",
      "The San\n",
      "Francisco Chief 14 rows skipped\n",
      "The San\n",
      "Juan\n",
      "Express 3 rows skipped\n",
      "The Scout\n",
      "The Missionary 122 rows skipped\n",
      "The Utah Parks Special 3 rows skipped\n",
      "The Angelo 3 rows skipped\n",
      "The Argonaut 54 rows skipped\n",
      "The Arizona Limited 8 rows skipped\n",
      "Trains\n",
      "6-75-92-97-23 and 24-98-91-76-5 8 rows skipped\n",
      "The California Special 17 rows skipped\n",
      "The California Special 7 rows skipped\n",
      "The Golden State Limited\n",
      "The Californian 156 rows skipped\n",
      "The Golden State 14 rows skipped\n",
      "The Golden State 12 rows skipped\n",
      "The Houstonian\n",
      "The Orleanean 3 rows skipped\n",
      "The Imperial 15 rows skipped\n",
      "The Lone Star 3 rows skipped\n",
      "The Louisiana Eagle\n",
      " 5 rows skipped\n",
      "The\n",
      "Streamlined Meteor 8 rows skipped\n",
      "The Morning Star 8 rows skipped\n",
      "The Ranger 15 rows skipped\n",
      "The Sam Houston Zephyr\n",
      "The Texas Rocket 2 rows skipped\n",
      "The Sam Houston Zephyr\n",
      "The Twin Star\n",
      "Rocket\n",
      "Trains 11 and 12 5 rows skipped\n",
      "The SunbeamThe Hustler 2 rows skipped\n",
      "The Sunset Limited 12 rows skipped\n",
      "The Sunset Limited 14 rows skipped\n",
      "Before the Fall 26 rows skipped\n",
      "Paradise Lost 14 rows skipped\n",
      "The Train From Hell 6 rows skipped\n",
      "A Redemption, of Sorts 6 rows skipped\n",
      "The Texas Chief 42 rows skipped\n",
      "The Texas Chief 10 rows skipped\n",
      "The Texas Chief 8 rows skipped\n",
      "The Texas Eagles 15 rows skipped\n",
      "The Texas Eagles 14 rows skipped\n",
      "The Texas Eagles\n",
      "The Sunshine Special 61 rows skipped\n",
      "The Texas Eagle 15 rows skipped\n",
      "The Texas Special 9 rows skipped\n",
      "The Texas Special\n",
      "The Bluebonnet 14 rows skipped\n",
      "The Texas Special\n",
      "Trains 5 & 6 7 rows skipped\n",
      "The Texas Zephyr 8 rows skipped\n",
      "The Texas ZephyrTrains 27-7 and 8-28 8 rows skipped\n",
      "The Twin Star Rocket 6 rows skipped\n",
      "The Twin Star Rocket 9 rows skipped\n",
      "The Twin\n",
      "Star Rocket 13 rows skipped\n",
      "Error parsing dump/concourse/track9/mailto:eric@streamlinerschedules.com: 'NoneType' object has no attribute 'find_all'\n",
      "Passenger\n",
      "Service 4 rows skipped\n",
      "The Chili Line 1 rows skipped\n",
      "The \"Chippy\" 2 rows skipped\n",
      "Mixed\n",
      "Trains 1\n",
      "and 2 1 rows skipped\n",
      "The Cannonball\n",
      "Long Island Railroad Service 2 rows skipped\n",
      "Mixed\n",
      "Local Trains 71 and 72 1 rows skipped\n",
      "The Silverton 1 rows skipped\n",
      "The Silverton 1 rows skipped\n",
      "The Steptoe Valley Flyer 2 rows skipped\n",
      "Passenger\n",
      "Service  7 rows skipped\n",
      "Trains\n",
      "14, 15, 17, 18 19 rows skipped\n"
     ]
    }
   ],
   "source": [
    "file_name_to_name_and_schedule = {}\n",
    "for file in all_train_files:\n",
    "    if \"track10\" in file or \"track11\" in file:\n",
    "        # This is Mexico and/or Europe\n",
    "        continue\n",
    "    try:\n",
    "        train_name, stops = parse_schedule(file)\n",
    "        file_name_to_name_and_schedule[file] = (train_name, stops)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file}: {e}\")\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "timezones = {\"(ET)\", \"(MT)\", \"(CT)\", \"(PT)\", \"(AT)\", \"(EDT)\", \"(CST)\", \"(CDT)\", \"(EST)\", \"(PST)\", \"(MST)\", \"(PDT)\", \"(MST)\", \"(AST)\"}\n",
    "def clean_station_name(station):\n",
    "    for t in timezones:\n",
    "        station = station.replace(t, \"\")\n",
    "    return station.replace(\"\\r\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_station_names = set()\n",
    "for _, stops in file_name_to_name_and_schedule.values():\n",
    "    all_station_names.update(stops[\"station\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_station_names = {clean_station_name(s) for s in all_station_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_table = pd.read_csv(\"uscities.csv\")\n",
    "\n",
    "def get_matching_city(city, state):\n",
    "    return cities_table[(cities_table[\"city\"] == city) & (cities_table[\"state_id\"] == state)]\n",
    "\n",
    "unmatched_stations = []\n",
    "\n",
    "station_name_to_coords = {}\n",
    "for station in clean_station_names:\n",
    "    s = station.split(\",\")\n",
    "    if len(s) != 2:\n",
    "        continue\n",
    "    city = s[0]\n",
    "    state = s[1][1:3]\n",
    "\n",
    "    match = get_matching_city(city, state)\n",
    "    if len(match) == 0:\n",
    "        unmatched_stations.append(station)\n",
    "        continue\n",
    "    station_name_to_coords[station] = (match.iloc[0][\"lat\"], match.iloc[0][\"lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_number</th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>New York, NY (Penna. Sta.) (ET)</td>\n",
       "      <td>12 30P</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176(3rd)</td>\n",
       "      <td>New York, NY (Penna. Sta.) (ET)</td>\n",
       "      <td>4 45P</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>12 45P</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176(3rd)</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>4 29P</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>Trenton, NJ</td>\n",
       "      <td>1 31P</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>48</td>\n",
       "      <td>Laurel, MS</td>\n",
       "      <td>11 04A</td>\n",
       "      <td>209.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>47</td>\n",
       "      <td>Hattiesburg, MS</td>\n",
       "      <td>5 43P</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>48</td>\n",
       "      <td>Hattiesburg, MS</td>\n",
       "      <td>10 30A</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>47</td>\n",
       "      <td>New Orleans, LA (Terminal\\r\\nSta.) (CT)</td>\n",
       "      <td>8 15P</td>\n",
       "      <td>354.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>48</td>\n",
       "      <td>New Orleans, LA (Terminal\\r\\nSta.) (CT)</td>\n",
       "      <td>8 00A</td>\n",
       "      <td>354.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_number                                  station    time  miles\n",
       "0            125          New York, NY (Penna. Sta.) (ET)  12 30P    0.0\n",
       "1       176(3rd)          New York, NY (Penna. Sta.) (ET)   4 45P    0.0\n",
       "2            125                               Newark, NJ  12 45P   10.0\n",
       "3       176(3rd)                               Newark, NJ   4 29P   10.0\n",
       "4            125                              Trenton, NJ   1 31P   58.1\n",
       "..           ...                                      ...     ...    ...\n",
       "97            48                               Laurel, MS  11 04A  209.1\n",
       "98            47                          Hattiesburg, MS   5 43P  238.0\n",
       "99            48                          Hattiesburg, MS  10 30A  238.0\n",
       "100           47  New Orleans, LA (Terminal\\r\\nSta.) (CT)   8 15P  354.6\n",
       "101           48  New Orleans, LA (Terminal\\r\\nSta.) (CT)   8 00A  354.6\n",
       "\n",
       "[102 rows x 4 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = file_name_to_name_and_schedule[\"dump/concourse/track1/birmspecial194112.html\"][1]\n",
    "schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group by departure station in this format:\n",
    "\n",
    "```ts\n",
    "type Coords = [number, number, number?] // [x, y, z?]\n",
    "type Route = {\n",
    "  departureTime: number // seconds since midnight (choose a timezone and stick with it)\n",
    "  departureCoords: Coords\n",
    "  arrivalTime: number // seconds since midnight (choose a timezone and stick with it)\n",
    "  arrivalCoords: Coords\n",
    "\n",
    "  // optional fields if we have the data for it\n",
    "  trainIdentifier?: string // name or id\n",
    "  departureIdentifier?: string // station name\n",
    "  arrivalIdentifier?: string // station name\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_seconds(time_str):\n",
    "    \"\"\"Converts a time string in the format 'HH MMX' (e.g., '3 22P') to seconds past midnight.\n",
    "  \n",
    "    Args:\n",
    "      time_str: The time string to convert.\n",
    "  \n",
    "    Returns:\n",
    "      The number of seconds past midnight.\n",
    "    \"\"\"\n",
    "    s = time_str.lstrip(\"F\").replace(\"\\n\", \" \").strip().split(\" \")\n",
    "    if len(s) != 2:\n",
    "        print(\"INVALID TIME PASSED IN\", time_str, len(time_str))\n",
    "        1 / 0\n",
    "\n",
    "    hour, minute = s \n",
    "    hour = int(hour)\n",
    "\n",
    "    if len(minute) > 2:\n",
    "        period = minute[2]\n",
    "    else:\n",
    "        period = \"A\"\n",
    "    minute = int(minute[:2])\n",
    "\n",
    "    if period == 'P' and hour != 12:\n",
    "      hour += 12\n",
    "    elif period == 'A' and hour == 12:\n",
    "      hour = 0\n",
    "\n",
    "    return hour * 3600 + minute * 60\n",
    "\n",
    "\n",
    "def maybe_get_next_stop(group, current_stop):\n",
    "    for i in range(current_stop + 1, len(group)):\n",
    "        if clean_station_name(group.iloc[i][\"station\"]) in station_name_to_coords:\n",
    "            return group.iloc[i]\n",
    "    return None\n",
    "    \n",
    "def get_next_stop_with_time(group, current_stop):\n",
    "    for i in range(current_stop + 1, len(group)):\n",
    "        if group.iloc[i][\"time\"] != \"F\" and len(group.iloc[i][\"miles\"]) > 0:\n",
    "            return group.iloc[i]\n",
    "    return None\n",
    "\n",
    "\n",
    "def schedule_to_routes(train_name, schedule):\n",
    "    departure_station_to_route = {}\n",
    "\n",
    "    for _, group in schedule.groupby('train_number'):\n",
    "        last_entry_with_time = None\n",
    "        for i in range(len(group) - 1):\n",
    "            current_stop, next_stop = group.iloc[i], maybe_get_next_stop(group, i)\n",
    "            current_station  = clean_station_name(current_stop[\"station\"])\n",
    "\n",
    "            if current_station not in station_name_to_coords or next_stop is None:\n",
    "                continue\n",
    "            next_station = clean_station_name(next_stop[\"station\"])\n",
    "\n",
    "\n",
    "\n",
    "            if current_stop[\"time\"] == \"F\":\n",
    "                # Impute the current time based on the last and next entry with time\n",
    "                next_stop_with_time = get_next_stop_with_time(group, i)\n",
    "                if last_entry_with_time is None or next_stop_with_time is None:\n",
    "                    print(\"ERROR\", current_stop)\n",
    "                    continue\n",
    "\n",
    "                distance_with_time = float(next_stop_with_time[\"miles\"]) - float(last_entry_with_time[\"miles\"])\n",
    "                miles_per_second = distance_with_time / (time_to_seconds(next_stop_with_time[\"time\"]) - time_to_seconds(last_entry_with_time[\"time\"]))\n",
    "\n",
    "                distance_elapsed = float(current_stop[\"miles\"]) - float(last_entry_with_time[\"miles\"])\n",
    "                time_elapsed = distance_elapsed / miles_per_second\n",
    "\n",
    "                departure_time = time_elapsed + time_to_seconds(last_entry_with_time[\"time\"])\n",
    "            else:\n",
    "                departure_time = time_to_seconds(current_stop[\"time\"])\n",
    "                last_entry_with_time = current_stop\n",
    "\n",
    "\n",
    "\n",
    "            if next_stop[\"time\"] == \"F\":\n",
    "                # Impute the current time based on the last and next entry with time\n",
    "                next_stop_with_time = get_next_stop_with_time(group, i)\n",
    "                if last_entry_with_time is None or next_stop_with_time is None:\n",
    "                    print(\"ERROR\", current_stop)\n",
    "                    continue\n",
    "\n",
    "                distance_with_time = float(next_stop_with_time[\"miles\"]) - float(last_entry_with_time[\"miles\"])\n",
    "                miles_per_second = distance_with_time / (time_to_seconds(next_stop_with_time[\"time\"]) - time_to_seconds(last_entry_with_time[\"time\"]))\n",
    "\n",
    "                distance_elapsed = float(next_stop[\"miles\"]) - float(last_entry_with_time[\"miles\"])\n",
    "                time_elapsed = distance_elapsed / miles_per_second\n",
    "\n",
    "                arrival_time = time_elapsed + time_to_seconds(last_entry_with_time[\"time\"])\n",
    "            else:\n",
    "                arrival_time = time_to_seconds(next_stop[\"time\"])\n",
    "\n",
    "            \n",
    "            route = {\n",
    "                'departureTime': departure_time,\n",
    "                'departureCoords': list(station_name_to_coords[current_station]),\n",
    "                'departureIdentifier': current_station,\n",
    "\n",
    "                'arrivalTime':  arrival_time,\n",
    "                'arrivalCoords': list(station_name_to_coords[next_station]),\n",
    "                'arrivalIdentifier': next_station,\n",
    "\n",
    "                'trainName': train_name,\n",
    "                'trainNumber': current_stop[\"train_number\"]\n",
    "            }\n",
    "            if current_station in departure_station_to_route:\n",
    "                departure_station_to_route[current_station].append(route)\n",
    "            else:\n",
    "                departure_station_to_route[current_station] = [route]\n",
    "    return departure_station_to_route\n",
    "\n",
    "routes = schedule_to_routes(\"The Birmingham Special\", schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump/concourse/track1/birmspecial194112.html\n",
      "dump/concourse/track1/carolinaspecial196410.html\n",
      "dump/concourse/track1/citymemphis195008.html\n",
      "dump/concourse/track1/cityneworl194706.html\n",
      "dump/concourse/track1/cityneworl197104.html\n",
      "dump/concourse/track1/crescent195008.html\n",
      "dump/concourse/track1/crescent197104.html\n",
      "dump/concourse/track1/crescent197303.html\n",
      "dump/concourse/track1/georgewash196706.html\n",
      "dump/concourse/track1/georgian196308.html\n",
      "dump/concourse/track1/gulfcoastrebel195008.html\n",
      "dump/concourse/track1/humbird194706.html\n",
      "dump/concourse/track1/humbird196308.html\n",
      "dump/concourse/track1/pan-am192701.html\n",
      "dump/concourse/track1/pan-am195407.html\n",
      "dump/concourse/track1/piedmontltd197303.html\n",
      "dump/concourse/track1/powhatan195008.html\n",
      "dump/concourse/track1/rebel193809.html\n",
      "dump/concourse/track1/rebel195304.html\n",
      "dump/concourse/track1/silvercomet194706.html\n",
      "dump/concourse/track1/soubelle194106.html\n",
      "dump/concourse/track1/soubelle196803.html\n",
      "dump/concourse/track1/southerner194112.html\n",
      "dump/concourse/track1/tennessean195212.html\n",
      "dump/concourse/track2/championec194106.html\n",
      "dump/concourse/track2/championwc194106.html\n",
      "dump/concourse/track2/champion197104.html\n",
      "dump/concourse/track2/citymiami194106.html\n",
      "dump/concourse/track2/citymiami197104.html\n",
      "dump/concourse/track2/delmarva194310.html\n",
      "dump/concourse/track2/dixieflag194106.html\n",
      "dump/concourse/track2/floridaspecial194912.html\n",
      "dump/concourse/track2/gulfwind194912.html\n",
      "dump/concourse/track2/gulfwind197104.html\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[342], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name, (name, schedule) \u001b[38;5;129;01min\u001b[39;00m file_name_to_name_and_schedule\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file_name)\n\u001b[0;32m----> 5\u001b[0m     routes \u001b[38;5;241m=\u001b[39m schedule_to_routes(name, schedule)\n\u001b[1;32m      6\u001b[0m     all_routes[file_name] \u001b[38;5;241m=\u001b[39m routes\n",
      "Cell \u001b[0;32mIn[341], line 87\u001b[0m, in \u001b[0;36mschedule_to_routes\u001b[0;34m(train_name, schedule)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_stop)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m distance_with_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(next_stop_with_time[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(last_entry_with_time[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m miles_per_second \u001b[38;5;241m=\u001b[39m distance_with_time \u001b[38;5;241m/\u001b[39m (time_to_seconds(next_stop_with_time[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m time_to_seconds(last_entry_with_time[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     90\u001b[0m distance_elapsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(next_stop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mfloat\u001b[39m(last_entry_with_time[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmiles\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "all_routes = {}\n",
    "\n",
    "for file_name, (name, schedule) in file_name_to_name_and_schedule.items():\n",
    "    print(file_name)\n",
    "    routes = schedule_to_routes(name, schedule)\n",
    "    all_routes[file_name] = routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(i) for i in all_routes.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = []\n",
    "for routes in all_routes.values():\n",
    "    for route in routes.values():\n",
    "        flattened.extend(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"routes.json\", \"w+\") as f:\n",
    "    json.dump(flattened, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2413"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattened)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
