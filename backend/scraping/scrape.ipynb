{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "path_prefix = \"dump/\"\n",
    "base_url = \"http://www.streamlinerschedules.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded\n"
     ]
    }
   ],
   "source": [
    "def download_track_pages():\n",
    "    track_pages = [f\"concourse/track{i}\" for i in range(1, 13)]\n",
    "    for page in track_pages:\n",
    "        Path(path_prefix + page).mkdir(exist_ok=True, parents=True)\n",
    "        with open(f\"{path_prefix}{page}/index.html\", \"wb+\") as f:\n",
    "            f.write(requests.get(f\"{base_url}{page}/index.html\").content)\n",
    "\n",
    "check_file = Path(f\"{path_prefix}/concourse/track1/index.html\")\n",
    "\n",
    "if check_file.exists() and check_file.stat().st_size > 0:\n",
    "    print(\"Already downloaded\")\n",
    "else:\n",
    "    # download_track_pages()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_pages = [f\"concourse/track{i}/index.html\" for i in range(1, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_prefix + track_pages[0], \"rb\") as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list like \"birmspecial194112.html\", \"carolinaspecial196410.html\", etc\n",
    "def get_train_links(soup):\n",
    "    relative_links = []\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        href = a.get(\"href\")\n",
    "        if href is not None and \"..\" not in href and \"http://\" not in href:\n",
    "            relative_links.append(href)\n",
    "    return relative_links\n",
    "\n",
    "def get_link(relative_link, page):\n",
    "    page = page.rstrip(\"index.html\")\n",
    "    return f\"{base_url}{page}{relative_link}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_child_pages(page):\n",
    "    with open(path_prefix + page, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "        links = get_train_links(soup)\n",
    "        for link in links:\n",
    "            with open(f\"{path_prefix}{page.rstrip('index.html')}/{link}\", \"wb+\") as f:\n",
    "                f.write(requests.get(get_link(link, page)).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birmingham Special\n",
      " 125\n",
      " 176(3rd)\n",
      " 17\n",
      " 18\n",
      " 6\n",
      " 5\n",
      " 35\n",
      " 36\n",
      " 47\n",
      " 48\n"
     ]
    }
   ],
   "source": [
    "def parse_schedule(schedule_filename):\n",
    "    with open(schedule_filename, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "    \n",
    "    train_name = soup.find(\"h1\", id=\"trainname\").text\n",
    "    print(train_name)\n",
    "\n",
    "    # TODO: Date\n",
    "    description_element = soup.find('h3', id='rrdate')\n",
    "\n",
    "    table = soup.find('table')\n",
    "    train_numbers = table.find_all(\"td\", class_=\"trainnum\")\n",
    "    for train_number in train_numbers:\n",
    "        print(train_number.text)\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parse_schedule(\"dump/concourse/track1/birmspecial194112.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birmingham Special\n",
      " 125\n",
      " 176(3rd)\n",
      " 17\n",
      " 18\n",
      " 6\n",
      " 5\n",
      " 35\n",
      " 36\n",
      " 47\n",
      " 48\n"
     ]
    }
   ],
   "source": [
    "with open(\"dump/concourse/track1/birmspecial194112.html\", \"rb\") as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "train_name = soup.find(\"h1\", id=\"trainname\").text\n",
    "print(train_name)\n",
    "\n",
    "description_element = soup.find('h3', id='rrdate')\n",
    "table = soup.find('table')\n",
    "\n",
    "train_numbers = table.find_all(\"td\", class_=\"trainnum\")\n",
    "for train_number in train_numbers:\n",
    "    print(train_number.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_number</th>\n",
       "      <th>station</th>\n",
       "      <th>time</th>\n",
       "      <th>miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>New York, NY (Penna. Sta.) (ET)</td>\n",
       "      <td>\\r\\n12 30P</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176(3rd)</td>\n",
       "      <td>New York, NY (Penna. Sta.) (ET)</td>\n",
       "      <td>\\r\\n4 45P</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>\\r\\n12 45P</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176(3rd)</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>\\r\\n4 29P</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>Trenton, NJ</td>\n",
       "      <td>\\r\\n1 31P</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>48</td>\n",
       "      <td>Laurel, MS</td>\n",
       "      <td>11 04A</td>\n",
       "      <td>209.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>47</td>\n",
       "      <td>Hattiesburg, MS</td>\n",
       "      <td>\\r\\n5 43P</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>48</td>\n",
       "      <td>Hattiesburg, MS</td>\n",
       "      <td>10 30A</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>47</td>\n",
       "      <td>New Orleans, LA (Terminal\\r\\nSta.) (CT)</td>\n",
       "      <td>\\r\\n8 15P</td>\n",
       "      <td>354.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>48</td>\n",
       "      <td>New Orleans, LA (Terminal\\r\\nSta.) (CT)</td>\n",
       "      <td>8 00A</td>\n",
       "      <td>354.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_number                                   station        time   miles\n",
       "0            125           New York, NY (Penna. Sta.) (ET)  \\r\\n12 30P     0.0\n",
       "1       176(3rd)           New York, NY (Penna. Sta.) (ET)   \\r\\n4 45P     0.0\n",
       "2            125                                Newark, NJ  \\r\\n12 45P    10.0\n",
       "3       176(3rd)                                Newark, NJ   \\r\\n4 29P    10.0\n",
       "4            125                               Trenton, NJ   \\r\\n1 31P    58.1\n",
       "..           ...                                       ...         ...     ...\n",
       "113           48                                Laurel, MS      11 04A   209.1\n",
       "114           47                           Hattiesburg, MS   \\r\\n5 43P   238.0\n",
       "115           48                           Hattiesburg, MS      10 30A   238.0\n",
       "116           47   New Orleans, LA (Terminal\\r\\nSta.) (CT)   \\r\\n8 15P   354.6\n",
       "117           48   New Orleans, LA (Terminal\\r\\nSta.) (CT)       8 00A   354.6\n",
       "\n",
       "[118 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = pd.DataFrame(columns=[\"train_number\", \"station\", \"time\", \"miles\"])\n",
    "\n",
    "rows = table.find_all(\"tr\")\n",
    "for i, header in enumerate(rows[1].find_all(\"td\")):\n",
    "    if header.text == \"Miles\":\n",
    "        miles_index = i\n",
    "        station_index = i + 1\n",
    "\n",
    "for row in rows:\n",
    "    if row.find(\"td\", class_=\"trainnum\") is not None:\n",
    "        train_nums = [t.text.strip() for t in row.find_all(\"td\", class_=\"trainnum\")]\n",
    "        continue\n",
    "    if row.find(\"td\", class_=\"times\") is None:\n",
    "        continue\n",
    "    times = row.find_all(\"td\", class_=\"times\")\n",
    "\n",
    "    miles = row.find_all(\"td\")[miles_index].text\n",
    "    station = row.find_all(\"td\")[station_index].text\n",
    "\n",
    "    for num, time in zip(train_nums, times):\n",
    "        stops = stops._append({\"train_number\": num, \"station\": station, \"time\": time.text, \"miles\": miles}, ignore_index=True)\n",
    "    \n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               New York, NY (Penna. Sta.) (ET)\n",
       "1               New York, NY (Penna. Sta.) (ET)\n",
       "2                                    Newark, NJ\n",
       "3                                    Newark, NJ\n",
       "4                                   Trenton, NJ\n",
       "                         ...                   \n",
       "113                                  Laurel, MS\n",
       "114                             Hattiesburg, MS\n",
       "115                             Hattiesburg, MS\n",
       "116     New Orleans, LA (Terminal\\r\\nSta.) (CT)\n",
       "117     New Orleans, LA (Terminal\\r\\nSta.) (CT)\n",
       "Name: station, Length: 118, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"ttbody times\" style=\"font-weight: bold;\">\n",
       " 12 30P</td>,\n",
       " <td class=\"ttbody times\" style=\"font-weight: bold;\">\n",
       " 4 45P</td>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[2].find_all(\"td\", class_=\"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birmingham Special\n",
      "The Carolina Special\n",
      "The City of Memphis\n",
      "The City of New Orleans\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m file_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mlink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[38;5;28mopen\u001b[39m(file_location, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m train_name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "for page in track_pages:\n",
    "    with open(path_prefix + page, \"rb\") as f:\n",
    "        soup = BeautifulSoup(f, \"html.parser\")\n",
    "        links = get_train_links(soup)\n",
    "        for link in links:\n",
    "            file_location = f\"{path_prefix}{page.rstrip('index.html')}{link}\"\n",
    "            soup = BeautifulSoup(open(file_location, \"rb\"), \"html.parser\")\n",
    "            train_name = soup.find(\"h1\", id=\"trainname\").text\n",
    "            print(train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
